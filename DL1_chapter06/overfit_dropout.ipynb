{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adaptive-samba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2842046472190667\n",
      "=== epoch:1, train acc:0.09333333333333334, test acc:0.0867 ===\n",
      "train loss:2.291783144082516\n",
      "train loss:2.292956458089752\n",
      "train loss:2.281686891828774\n",
      "=== epoch:2, train acc:0.09333333333333334, test acc:0.0884 ===\n",
      "train loss:2.265591880944899\n",
      "train loss:2.2891986980040118\n",
      "train loss:2.2763759331868947\n",
      "=== epoch:3, train acc:0.09666666666666666, test acc:0.0892 ===\n",
      "train loss:2.2691839554907647\n",
      "train loss:2.3011029468348383\n",
      "train loss:2.2775860914179105\n",
      "=== epoch:4, train acc:0.1, test acc:0.0906 ===\n",
      "train loss:2.2848380531509207\n",
      "train loss:2.284821909654543\n",
      "train loss:2.283278720359066\n",
      "=== epoch:5, train acc:0.1, test acc:0.0918 ===\n",
      "train loss:2.2850439257601285\n",
      "train loss:2.284408327519771\n",
      "train loss:2.2808413235385467\n",
      "=== epoch:6, train acc:0.10333333333333333, test acc:0.0924 ===\n",
      "train loss:2.27967676197394\n",
      "train loss:2.2748505243375674\n",
      "train loss:2.2793762894010943\n",
      "=== epoch:7, train acc:0.11, test acc:0.0952 ===\n",
      "train loss:2.2789858400125382\n",
      "train loss:2.2927673361721155\n",
      "train loss:2.2815015822669604\n",
      "=== epoch:8, train acc:0.11, test acc:0.0969 ===\n",
      "train loss:2.270933339606957\n",
      "train loss:2.2962514706475203\n",
      "train loss:2.26824469601272\n",
      "=== epoch:9, train acc:0.11333333333333333, test acc:0.099 ===\n",
      "train loss:2.283484453518735\n",
      "train loss:2.277481704693193\n",
      "train loss:2.264980123320923\n",
      "=== epoch:10, train acc:0.10666666666666667, test acc:0.1002 ===\n",
      "train loss:2.2721455902455294\n",
      "train loss:2.284724033887782\n",
      "train loss:2.2745298266781306\n",
      "=== epoch:11, train acc:0.11, test acc:0.1026 ===\n",
      "train loss:2.2786291023348655\n",
      "train loss:2.2806999712801477\n",
      "train loss:2.2827911823403824\n",
      "=== epoch:12, train acc:0.11666666666666667, test acc:0.1055 ===\n",
      "train loss:2.257489928082488\n",
      "train loss:2.2741135230227836\n",
      "train loss:2.2663017944931645\n",
      "=== epoch:13, train acc:0.12666666666666668, test acc:0.1085 ===\n",
      "train loss:2.2791341976246655\n",
      "train loss:2.2661438556024724\n",
      "train loss:2.2684993389088857\n",
      "=== epoch:14, train acc:0.13333333333333333, test acc:0.11 ===\n",
      "train loss:2.2721523865651796\n",
      "train loss:2.2735879732034885\n",
      "train loss:2.298138032908088\n",
      "=== epoch:15, train acc:0.12666666666666668, test acc:0.1111 ===\n",
      "train loss:2.2720456754373406\n",
      "train loss:2.2694330302266277\n",
      "train loss:2.259111928867572\n",
      "=== epoch:16, train acc:0.12333333333333334, test acc:0.1131 ===\n",
      "train loss:2.2858689126102343\n",
      "train loss:2.2628550738872972\n",
      "train loss:2.270361154910222\n",
      "=== epoch:17, train acc:0.12666666666666668, test acc:0.1149 ===\n",
      "train loss:2.2697565222422442\n",
      "train loss:2.2763483709341297\n",
      "train loss:2.2560015098787156\n",
      "=== epoch:18, train acc:0.13333333333333333, test acc:0.119 ===\n",
      "train loss:2.262925778136731\n",
      "train loss:2.256265359647385\n",
      "train loss:2.2771348042021544\n",
      "=== epoch:19, train acc:0.14, test acc:0.1227 ===\n",
      "train loss:2.27068951747498\n",
      "train loss:2.271033423461671\n",
      "train loss:2.269064623243077\n",
      "=== epoch:20, train acc:0.14666666666666667, test acc:0.1247 ===\n",
      "train loss:2.2748632761291265\n",
      "train loss:2.271832202198403\n",
      "train loss:2.258321536332189\n",
      "=== epoch:21, train acc:0.14, test acc:0.1274 ===\n",
      "train loss:2.2766908262808343\n",
      "train loss:2.266654301669061\n",
      "train loss:2.2708704379297955\n",
      "=== epoch:22, train acc:0.14333333333333334, test acc:0.1284 ===\n",
      "train loss:2.2654151350690035\n",
      "train loss:2.2586302835016996\n",
      "train loss:2.2775339385586935\n",
      "=== epoch:23, train acc:0.14, test acc:0.132 ===\n",
      "train loss:2.265755529482064\n",
      "train loss:2.2639590856743834\n",
      "train loss:2.2722930127713328\n",
      "=== epoch:24, train acc:0.14, test acc:0.1352 ===\n",
      "train loss:2.2546669803241524\n",
      "train loss:2.2762676240332764\n",
      "train loss:2.257156170843789\n",
      "=== epoch:25, train acc:0.14, test acc:0.1394 ===\n",
      "train loss:2.2626755680918555\n",
      "train loss:2.2648620506452133\n",
      "train loss:2.261658010892101\n",
      "=== epoch:26, train acc:0.15666666666666668, test acc:0.1447 ===\n",
      "train loss:2.27028954559337\n",
      "train loss:2.262499385941008\n",
      "train loss:2.2788008314760133\n",
      "=== epoch:27, train acc:0.16, test acc:0.1497 ===\n",
      "train loss:2.262505223596617\n",
      "train loss:2.2686430254760683\n",
      "train loss:2.2604057099898562\n",
      "=== epoch:28, train acc:0.16333333333333333, test acc:0.1542 ===\n",
      "train loss:2.2551859859188665\n",
      "train loss:2.2667773279934567\n",
      "train loss:2.2645847059757274\n",
      "=== epoch:29, train acc:0.17333333333333334, test acc:0.1537 ===\n",
      "train loss:2.2553056066770383\n",
      "train loss:2.2662787486113625\n",
      "train loss:2.257076575622452\n",
      "=== epoch:30, train acc:0.17, test acc:0.1578 ===\n",
      "train loss:2.2647325396092928\n",
      "train loss:2.2594558476623545\n",
      "train loss:2.2497811201106366\n",
      "=== epoch:31, train acc:0.18, test acc:0.1594 ===\n",
      "train loss:2.2497237345368166\n",
      "train loss:2.258853841240787\n",
      "train loss:2.2468439470716506\n",
      "=== epoch:32, train acc:0.18666666666666668, test acc:0.1631 ===\n",
      "train loss:2.269398293900004\n",
      "train loss:2.2553454739945233\n",
      "train loss:2.243696911952845\n",
      "=== epoch:33, train acc:0.19, test acc:0.1694 ===\n",
      "train loss:2.2549019607387932\n",
      "train loss:2.252479420663777\n",
      "train loss:2.265232936323548\n",
      "=== epoch:34, train acc:0.19, test acc:0.1718 ===\n",
      "train loss:2.2477230481427837\n",
      "train loss:2.2616923319777964\n",
      "train loss:2.251825270378974\n",
      "=== epoch:35, train acc:0.19666666666666666, test acc:0.1761 ===\n",
      "train loss:2.242088342505652\n",
      "train loss:2.2563436819807063\n",
      "train loss:2.2413649506685562\n",
      "=== epoch:36, train acc:0.21, test acc:0.183 ===\n",
      "train loss:2.2484886209527333\n",
      "train loss:2.2559557857691455\n",
      "train loss:2.2497672847108787\n",
      "=== epoch:37, train acc:0.22666666666666666, test acc:0.1861 ===\n",
      "train loss:2.253473678193337\n",
      "train loss:2.2472252027530972\n",
      "train loss:2.250697712333588\n",
      "=== epoch:38, train acc:0.24, test acc:0.1916 ===\n",
      "train loss:2.2470096019474046\n",
      "train loss:2.2583582763188543\n",
      "train loss:2.257509197240703\n",
      "=== epoch:39, train acc:0.26, test acc:0.1955 ===\n",
      "train loss:2.2365368775504018\n",
      "train loss:2.257400218488988\n",
      "train loss:2.2463035167135863\n",
      "=== epoch:40, train acc:0.25333333333333335, test acc:0.2003 ===\n",
      "train loss:2.25076198768434\n",
      "train loss:2.2505438296719062\n",
      "train loss:2.244007990454275\n",
      "=== epoch:41, train acc:0.27, test acc:0.2049 ===\n",
      "train loss:2.226901899288502\n",
      "train loss:2.2407753591672215\n",
      "train loss:2.231807130145508\n",
      "=== epoch:42, train acc:0.27, test acc:0.2107 ===\n",
      "train loss:2.259628248332773\n",
      "train loss:2.253495242805135\n",
      "train loss:2.259817287965479\n",
      "=== epoch:43, train acc:0.27666666666666667, test acc:0.2156 ===\n",
      "train loss:2.241569667683098\n",
      "train loss:2.242342206799372\n",
      "train loss:2.256674683672998\n",
      "=== epoch:44, train acc:0.29333333333333333, test acc:0.2206 ===\n",
      "train loss:2.2543418991797814\n",
      "train loss:2.2430912572988864\n",
      "train loss:2.250773095789719\n",
      "=== epoch:45, train acc:0.2833333333333333, test acc:0.2275 ===\n",
      "train loss:2.239913810229241\n",
      "train loss:2.261596046807988\n",
      "train loss:2.258361760731147\n",
      "=== epoch:46, train acc:0.3, test acc:0.2292 ===\n",
      "train loss:2.228870742904499\n",
      "train loss:2.238386701140266\n",
      "train loss:2.2442340249009476\n",
      "=== epoch:47, train acc:0.31666666666666665, test acc:0.234 ===\n",
      "train loss:2.2504986506394142\n",
      "train loss:2.2352362531566716\n",
      "train loss:2.234517196526287\n",
      "=== epoch:48, train acc:0.31, test acc:0.2392 ===\n",
      "train loss:2.238931333344235\n",
      "train loss:2.2389961777269387\n",
      "train loss:2.23509630685194\n",
      "=== epoch:49, train acc:0.32, test acc:0.2419 ===\n",
      "train loss:2.25303997331745\n",
      "train loss:2.2324361141920424\n",
      "train loss:2.242484160645436\n",
      "=== epoch:50, train acc:0.31, test acc:0.2441 ===\n",
      "train loss:2.2673323964942695\n",
      "train loss:2.2385338960124006\n",
      "train loss:2.232322023699481\n",
      "=== epoch:51, train acc:0.33, test acc:0.25 ===\n",
      "train loss:2.2589147541098553\n",
      "train loss:2.2380140501082817\n",
      "train loss:2.239676812308884\n",
      "=== epoch:52, train acc:0.3333333333333333, test acc:0.2511 ===\n",
      "train loss:2.228001247394936\n",
      "train loss:2.251973425043646\n",
      "train loss:2.2326484518650256\n",
      "=== epoch:53, train acc:0.33666666666666667, test acc:0.2551 ===\n",
      "train loss:2.2402922803202663\n",
      "train loss:2.2349646588345005\n",
      "train loss:2.2209168433195248\n",
      "=== epoch:54, train acc:0.33666666666666667, test acc:0.2598 ===\n",
      "train loss:2.2191023799510017\n",
      "train loss:2.2488897909353436\n",
      "train loss:2.2413522750171184\n",
      "=== epoch:55, train acc:0.34, test acc:0.2627 ===\n",
      "train loss:2.2398615971122147\n",
      "train loss:2.2354470649976124\n",
      "train loss:2.2320252569737833\n",
      "=== epoch:56, train acc:0.35, test acc:0.2654 ===\n",
      "train loss:2.2409956472442802\n",
      "train loss:2.2342948252932815\n",
      "train loss:2.216620893224599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:57, train acc:0.36, test acc:0.2706 ===\n",
      "train loss:2.2291878547689556\n",
      "train loss:2.2333103364743434\n",
      "train loss:2.2273413008263554\n",
      "=== epoch:58, train acc:0.37333333333333335, test acc:0.2763 ===\n",
      "train loss:2.234998386973117\n",
      "train loss:2.2279557772450627\n",
      "train loss:2.228329524138823\n",
      "=== epoch:59, train acc:0.37666666666666665, test acc:0.2805 ===\n",
      "train loss:2.2185626465751636\n",
      "train loss:2.2318916974253575\n",
      "train loss:2.221146222307916\n",
      "=== epoch:60, train acc:0.38, test acc:0.2831 ===\n",
      "train loss:2.2359586759672205\n",
      "train loss:2.2121637050356746\n",
      "train loss:2.2293097848813686\n",
      "=== epoch:61, train acc:0.38666666666666666, test acc:0.2869 ===\n",
      "train loss:2.2112905503313107\n",
      "train loss:2.220062845711868\n",
      "train loss:2.2469312615241517\n",
      "=== epoch:62, train acc:0.39, test acc:0.2915 ===\n",
      "train loss:2.2297887043527047\n",
      "train loss:2.2465660915549237\n",
      "train loss:2.225271663236811\n",
      "=== epoch:63, train acc:0.39, test acc:0.2934 ===\n",
      "train loss:2.2285539426208745\n",
      "train loss:2.2136853921156754\n",
      "train loss:2.2261001204400768\n",
      "=== epoch:64, train acc:0.39666666666666667, test acc:0.2982 ===\n",
      "train loss:2.2148636483883037\n",
      "train loss:2.2196299027465702\n",
      "train loss:2.2251093269342697\n",
      "=== epoch:65, train acc:0.4, test acc:0.3015 ===\n",
      "train loss:2.2015774226491804\n",
      "train loss:2.2166906451977937\n",
      "train loss:2.1987054588778467\n",
      "=== epoch:66, train acc:0.4066666666666667, test acc:0.3032 ===\n",
      "train loss:2.2087116756688174\n",
      "train loss:2.2095913264252713\n",
      "train loss:2.220309948469231\n",
      "=== epoch:67, train acc:0.4033333333333333, test acc:0.3047 ===\n",
      "train loss:2.213511583975062\n",
      "train loss:2.2238620400026083\n",
      "train loss:2.210898149969943\n",
      "=== epoch:68, train acc:0.41, test acc:0.3084 ===\n",
      "train loss:2.209125966871706\n",
      "train loss:2.1938477557188842\n",
      "train loss:2.23059243509479\n",
      "=== epoch:69, train acc:0.4166666666666667, test acc:0.3109 ===\n",
      "train loss:2.223438447773788\n",
      "train loss:2.2185189543965933\n",
      "train loss:2.2226412526376733\n",
      "=== epoch:70, train acc:0.42333333333333334, test acc:0.3163 ===\n",
      "train loss:2.2239117228664202\n",
      "train loss:2.214460629250407\n",
      "train loss:2.211318024296278\n",
      "=== epoch:71, train acc:0.42, test acc:0.3156 ===\n",
      "train loss:2.205139793186682\n",
      "train loss:2.2248222068341192\n",
      "train loss:2.2104831381001744\n",
      "=== epoch:72, train acc:0.4266666666666667, test acc:0.3219 ===\n",
      "train loss:2.222083098142909\n",
      "train loss:2.2078553153879055\n",
      "train loss:2.220960375811497\n",
      "=== epoch:73, train acc:0.43, test acc:0.3232 ===\n",
      "train loss:2.209644215919582\n",
      "train loss:2.21028904083695\n",
      "train loss:2.2265467237471137\n",
      "=== epoch:74, train acc:0.43666666666666665, test acc:0.324 ===\n",
      "train loss:2.2267062534569115\n",
      "train loss:2.207976045120885\n",
      "train loss:2.2177343261770437\n",
      "=== epoch:75, train acc:0.44, test acc:0.3272 ===\n",
      "train loss:2.20718673457644\n",
      "train loss:2.194664321017311\n",
      "train loss:2.22717183151396\n",
      "=== epoch:76, train acc:0.43666666666666665, test acc:0.3291 ===\n",
      "train loss:2.225234278866081\n",
      "train loss:2.2054896539122226\n",
      "train loss:2.1915706659152896\n",
      "=== epoch:77, train acc:0.44333333333333336, test acc:0.333 ===\n",
      "train loss:2.212963155043825\n",
      "train loss:2.2099021770933613\n",
      "train loss:2.1949805175928465\n",
      "=== epoch:78, train acc:0.43666666666666665, test acc:0.3311 ===\n",
      "train loss:2.187357318356064\n",
      "train loss:2.1856874749288937\n",
      "train loss:2.1949364122724875\n",
      "=== epoch:79, train acc:0.4266666666666667, test acc:0.3269 ===\n",
      "train loss:2.190726754396355\n",
      "train loss:2.2051017412756138\n",
      "train loss:2.1902815202169683\n",
      "=== epoch:80, train acc:0.43, test acc:0.3281 ===\n",
      "train loss:2.202646217541917\n",
      "train loss:2.204982168753619\n",
      "train loss:2.1858453583044177\n",
      "=== epoch:81, train acc:0.43333333333333335, test acc:0.3253 ===\n",
      "train loss:2.2153168113253474\n",
      "train loss:2.213596570697058\n",
      "train loss:2.1887622249415317\n",
      "=== epoch:82, train acc:0.44, test acc:0.3268 ===\n",
      "train loss:2.191480159526675\n",
      "train loss:2.1754889776975492\n",
      "train loss:2.194496675507591\n",
      "=== epoch:83, train acc:0.44333333333333336, test acc:0.3284 ===\n",
      "train loss:2.1846649428371707\n",
      "train loss:2.1965907006458885\n",
      "train loss:2.1880850924851227\n",
      "=== epoch:84, train acc:0.44333333333333336, test acc:0.3263 ===\n",
      "train loss:2.181849412853264\n",
      "train loss:2.2172896273489324\n",
      "train loss:2.1833657426223794\n",
      "=== epoch:85, train acc:0.4533333333333333, test acc:0.335 ===\n",
      "train loss:2.1848523301965432\n",
      "train loss:2.203126373372786\n",
      "train loss:2.2144197649836745\n",
      "=== epoch:86, train acc:0.4533333333333333, test acc:0.3407 ===\n",
      "train loss:2.2005011715362683\n",
      "train loss:2.1829773958363043\n",
      "train loss:2.207111393663103\n",
      "=== epoch:87, train acc:0.4666666666666667, test acc:0.3474 ===\n",
      "train loss:2.2018210220404835\n",
      "train loss:2.167203553167395\n",
      "train loss:2.181766640652964\n",
      "=== epoch:88, train acc:0.4633333333333333, test acc:0.3453 ===\n",
      "train loss:2.1954491231360964\n",
      "train loss:2.2080379959853444\n",
      "train loss:2.192971100276334\n",
      "=== epoch:89, train acc:0.47, test acc:0.3513 ===\n",
      "train loss:2.1823853992770585\n",
      "train loss:2.167631349264636\n",
      "train loss:2.1589034582421207\n",
      "=== epoch:90, train acc:0.47333333333333333, test acc:0.3544 ===\n",
      "train loss:2.200662812999271\n",
      "train loss:2.1814147304773552\n",
      "train loss:2.1677498957463555\n",
      "=== epoch:91, train acc:0.4766666666666667, test acc:0.3597 ===\n",
      "train loss:2.177396205015805\n",
      "train loss:2.2023759434792805\n",
      "train loss:2.185939545618818\n",
      "=== epoch:92, train acc:0.4866666666666667, test acc:0.3653 ===\n",
      "train loss:2.160398896146769\n",
      "train loss:2.195936897883279\n",
      "train loss:2.1719390837840247\n",
      "=== epoch:93, train acc:0.4766666666666667, test acc:0.3619 ===\n",
      "train loss:2.171821360027059\n",
      "train loss:2.155682285634596\n",
      "train loss:2.1756518540423304\n",
      "=== epoch:94, train acc:0.4633333333333333, test acc:0.3624 ===\n",
      "train loss:2.179246289101216\n",
      "train loss:2.184534878747737\n",
      "train loss:2.1556009606487185\n",
      "=== epoch:95, train acc:0.46, test acc:0.3592 ===\n",
      "train loss:2.162859662098926\n",
      "train loss:2.1708376068149695\n",
      "train loss:2.1498763594458183\n",
      "=== epoch:96, train acc:0.4633333333333333, test acc:0.3588 ===\n",
      "train loss:2.178707725630801\n",
      "train loss:2.1481472858419117\n",
      "train loss:2.154871881868274\n",
      "=== epoch:97, train acc:0.47333333333333333, test acc:0.3603 ===\n",
      "train loss:2.1499179207495187\n",
      "train loss:2.1557513581139833\n",
      "train loss:2.168164333371372\n",
      "=== epoch:98, train acc:0.45666666666666667, test acc:0.3569 ===\n",
      "train loss:2.170702985366048\n",
      "train loss:2.181100814322873\n",
      "train loss:2.1473643628352894\n",
      "=== epoch:99, train acc:0.45666666666666667, test acc:0.3602 ===\n",
      "train loss:2.1387515454273385\n",
      "train loss:2.1653124227886797\n",
      "train loss:2.1642397398213857\n",
      "=== epoch:100, train acc:0.4533333333333333, test acc:0.3582 ===\n",
      "train loss:2.1555142861567265\n",
      "train loss:2.143058720298306\n",
      "train loss:2.1718358292578133\n",
      "=== epoch:101, train acc:0.45, test acc:0.3551 ===\n",
      "train loss:2.195132216826708\n",
      "train loss:2.126805268976943\n",
      "train loss:2.1417369463333924\n",
      "=== epoch:102, train acc:0.44666666666666666, test acc:0.3578 ===\n",
      "train loss:2.1509913980750155\n",
      "train loss:2.1579538765680955\n",
      "train loss:2.161965370326366\n",
      "=== epoch:103, train acc:0.4633333333333333, test acc:0.3587 ===\n",
      "train loss:2.1488919885109623\n",
      "train loss:2.152838013419611\n",
      "train loss:2.1333824567884285\n",
      "=== epoch:104, train acc:0.4633333333333333, test acc:0.3602 ===\n",
      "train loss:2.163586430519693\n",
      "train loss:2.167723492536274\n",
      "train loss:2.15486278186881\n",
      "=== epoch:105, train acc:0.4533333333333333, test acc:0.3581 ===\n",
      "train loss:2.148934817817711\n",
      "train loss:2.1643681432432453\n",
      "train loss:2.178115255646558\n",
      "=== epoch:106, train acc:0.45666666666666667, test acc:0.3591 ===\n",
      "train loss:2.1242489903305115\n",
      "train loss:2.1496659655817756\n",
      "train loss:2.131789984143145\n",
      "=== epoch:107, train acc:0.46, test acc:0.3622 ===\n",
      "train loss:2.1667694927033523\n",
      "train loss:2.1278029760274544\n",
      "train loss:2.100955906660803\n",
      "=== epoch:108, train acc:0.4666666666666667, test acc:0.3629 ===\n",
      "train loss:2.1369175801101172\n",
      "train loss:2.121881758592807\n",
      "train loss:2.152403787653963\n",
      "=== epoch:109, train acc:0.4633333333333333, test acc:0.3622 ===\n",
      "train loss:2.1682757899902656\n",
      "train loss:2.1649643128173035\n",
      "train loss:2.1706097929130874\n",
      "=== epoch:110, train acc:0.47, test acc:0.3634 ===\n",
      "train loss:2.1547991370404036\n",
      "train loss:2.133871430442552\n",
      "train loss:2.1212106218635567\n",
      "=== epoch:111, train acc:0.4666666666666667, test acc:0.3647 ===\n",
      "train loss:2.171975031185785\n",
      "train loss:2.133818291386066\n",
      "train loss:2.1452857944009343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:112, train acc:0.48, test acc:0.3665 ===\n",
      "train loss:2.170198456771903\n",
      "train loss:2.142832045461075\n",
      "train loss:2.134134569350297\n",
      "=== epoch:113, train acc:0.48333333333333334, test acc:0.3751 ===\n",
      "train loss:2.141188594625527\n",
      "train loss:2.1340525177173366\n",
      "train loss:2.1290773965680403\n",
      "=== epoch:114, train acc:0.5, test acc:0.3775 ===\n",
      "train loss:2.1129620149545474\n",
      "train loss:2.0885564222951136\n",
      "train loss:2.114241834689934\n",
      "=== epoch:115, train acc:0.49333333333333335, test acc:0.372 ===\n",
      "train loss:2.0870236892530674\n",
      "train loss:2.1205376627046295\n",
      "train loss:2.1534605177356454\n",
      "=== epoch:116, train acc:0.5, test acc:0.3724 ===\n",
      "train loss:2.1462540455807613\n",
      "train loss:2.125722580051966\n",
      "train loss:2.1132925143106096\n",
      "=== epoch:117, train acc:0.5033333333333333, test acc:0.3736 ===\n",
      "train loss:2.115816168557697\n",
      "train loss:2.1047001785638297\n",
      "train loss:2.115087158231028\n",
      "=== epoch:118, train acc:0.49666666666666665, test acc:0.3793 ===\n",
      "train loss:2.1011912093355467\n",
      "train loss:2.0972085327946686\n",
      "train loss:2.101312912069844\n",
      "=== epoch:119, train acc:0.49666666666666665, test acc:0.3751 ===\n",
      "train loss:2.127998659549563\n",
      "train loss:2.0805950742477815\n",
      "train loss:2.0932802944846483\n",
      "=== epoch:120, train acc:0.5, test acc:0.3807 ===\n",
      "train loss:2.1159752868652957\n",
      "train loss:2.10169194844873\n",
      "train loss:2.107024184221714\n",
      "=== epoch:121, train acc:0.5, test acc:0.3829 ===\n",
      "train loss:2.1120246264954163\n",
      "train loss:2.0783752908088293\n",
      "train loss:2.0931934884279992\n",
      "=== epoch:122, train acc:0.5, test acc:0.3837 ===\n",
      "train loss:2.093479892924041\n",
      "train loss:2.1058524957138305\n",
      "train loss:2.1783720108899285\n",
      "=== epoch:123, train acc:0.5, test acc:0.3864 ===\n",
      "train loss:2.096863096111756\n",
      "train loss:2.1064989241804977\n",
      "train loss:2.0471570412670834\n",
      "=== epoch:124, train acc:0.49666666666666665, test acc:0.3889 ===\n",
      "train loss:2.0945987205607013\n",
      "train loss:2.0760515484871025\n",
      "train loss:2.1053781285805644\n",
      "=== epoch:125, train acc:0.5033333333333333, test acc:0.3912 ===\n",
      "train loss:2.105100030675412\n",
      "train loss:2.0798464073558427\n",
      "train loss:2.081218742043251\n",
      "=== epoch:126, train acc:0.51, test acc:0.397 ===\n",
      "train loss:2.0920402139010092\n",
      "train loss:2.085139035068941\n",
      "train loss:2.10067849404888\n",
      "=== epoch:127, train acc:0.5033333333333333, test acc:0.395 ===\n",
      "train loss:2.0545879906664073\n",
      "train loss:2.0844091311634445\n",
      "train loss:2.083536005814191\n",
      "=== epoch:128, train acc:0.51, test acc:0.3974 ===\n",
      "train loss:2.0345492495767274\n",
      "train loss:2.125595359882289\n",
      "train loss:2.0925936106580014\n",
      "=== epoch:129, train acc:0.49666666666666665, test acc:0.3922 ===\n",
      "train loss:2.0845298174063442\n",
      "train loss:2.128017416442458\n",
      "train loss:2.069760303670134\n",
      "=== epoch:130, train acc:0.5, test acc:0.3961 ===\n",
      "train loss:2.068128991900357\n",
      "train loss:2.0684178651393417\n",
      "train loss:2.056772770717204\n",
      "=== epoch:131, train acc:0.5066666666666667, test acc:0.3951 ===\n",
      "train loss:2.0468174085636806\n",
      "train loss:2.0767818084725667\n",
      "train loss:2.09327957198014\n",
      "=== epoch:132, train acc:0.5066666666666667, test acc:0.4022 ===\n",
      "train loss:2.0859299388887127\n",
      "train loss:2.120635871697269\n",
      "train loss:2.08603295686945\n",
      "=== epoch:133, train acc:0.5133333333333333, test acc:0.4039 ===\n",
      "train loss:2.0707198163392677\n",
      "train loss:2.061892668988918\n",
      "train loss:2.09219330746069\n",
      "=== epoch:134, train acc:0.5166666666666667, test acc:0.4068 ===\n",
      "train loss:2.0473725183904214\n",
      "train loss:2.0621112928269607\n",
      "train loss:2.0574431261274895\n",
      "=== epoch:135, train acc:0.5166666666666667, test acc:0.4001 ===\n",
      "train loss:2.0896257205389457\n",
      "train loss:2.0667797937088785\n",
      "train loss:2.060102922358865\n",
      "=== epoch:136, train acc:0.52, test acc:0.4045 ===\n",
      "train loss:2.1236422780368414\n",
      "train loss:2.036678652252131\n",
      "train loss:2.10662272751055\n",
      "=== epoch:137, train acc:0.5233333333333333, test acc:0.409 ===\n",
      "train loss:2.0670851240148123\n",
      "train loss:2.061744716036466\n",
      "train loss:2.0348909824021506\n",
      "=== epoch:138, train acc:0.52, test acc:0.4106 ===\n",
      "train loss:2.0889610537068197\n",
      "train loss:2.0288030186779777\n",
      "train loss:2.0670657568296003\n",
      "=== epoch:139, train acc:0.5266666666666666, test acc:0.4167 ===\n",
      "train loss:2.0525149261499793\n",
      "train loss:2.0062027502089133\n",
      "train loss:2.059032009745884\n",
      "=== epoch:140, train acc:0.5166666666666667, test acc:0.4128 ===\n",
      "train loss:2.0616141616870274\n",
      "train loss:2.028906526200324\n",
      "train loss:2.0066834753649854\n",
      "=== epoch:141, train acc:0.5166666666666667, test acc:0.4083 ===\n",
      "train loss:2.0383173176099305\n",
      "train loss:2.010560700335382\n",
      "train loss:2.0164029813355726\n",
      "=== epoch:142, train acc:0.5133333333333333, test acc:0.4069 ===\n",
      "train loss:2.015765190583668\n",
      "train loss:1.9732860663494318\n",
      "train loss:1.9987711081337876\n",
      "=== epoch:143, train acc:0.5033333333333333, test acc:0.4017 ===\n",
      "train loss:2.0260350943957257\n",
      "train loss:2.0153736720379674\n",
      "train loss:2.0202817607306214\n",
      "=== epoch:144, train acc:0.49666666666666665, test acc:0.3986 ===\n",
      "train loss:2.0337088685457605\n",
      "train loss:2.0315585889718593\n",
      "train loss:1.9931066200643393\n",
      "=== epoch:145, train acc:0.5, test acc:0.3998 ===\n",
      "train loss:1.9985403868581324\n",
      "train loss:2.044763730638554\n",
      "train loss:2.0030878809370596\n",
      "=== epoch:146, train acc:0.5066666666666667, test acc:0.3997 ===\n",
      "train loss:1.9685028253124128\n",
      "train loss:1.9647712831777864\n",
      "train loss:1.9908695749972565\n",
      "=== epoch:147, train acc:0.49333333333333335, test acc:0.3984 ===\n",
      "train loss:2.0060331108493683\n",
      "train loss:1.993999621758305\n",
      "train loss:2.0372201875498517\n",
      "=== epoch:148, train acc:0.5, test acc:0.4013 ===\n",
      "train loss:2.023024199679997\n",
      "train loss:2.0371163905067413\n",
      "train loss:2.029067452430141\n",
      "=== epoch:149, train acc:0.5, test acc:0.4053 ===\n",
      "train loss:2.038676663646786\n",
      "train loss:1.9963692231523742\n",
      "train loss:1.9700993995419531\n",
      "=== epoch:150, train acc:0.5, test acc:0.4051 ===\n",
      "train loss:1.9610098924910968\n",
      "train loss:1.9862999064981859\n",
      "train loss:2.019656943516417\n",
      "=== epoch:151, train acc:0.49333333333333335, test acc:0.4033 ===\n",
      "train loss:1.9660209892673146\n",
      "train loss:2.053486393495436\n",
      "train loss:1.9764767340887286\n",
      "=== epoch:152, train acc:0.5, test acc:0.4056 ===\n",
      "train loss:2.0016248769169356\n",
      "train loss:1.9858123124994151\n",
      "train loss:1.971725563793553\n",
      "=== epoch:153, train acc:0.5033333333333333, test acc:0.4075 ===\n",
      "train loss:1.9646320822835557\n",
      "train loss:1.9866389302359784\n",
      "train loss:2.0164294746282585\n",
      "=== epoch:154, train acc:0.5033333333333333, test acc:0.4105 ===\n",
      "train loss:1.9777789199324067\n",
      "train loss:1.98185117159569\n",
      "train loss:1.9095696193440244\n",
      "=== epoch:155, train acc:0.5033333333333333, test acc:0.4055 ===\n",
      "train loss:1.9722959303299488\n",
      "train loss:1.9687902411563867\n",
      "train loss:1.9363243225561495\n",
      "=== epoch:156, train acc:0.51, test acc:0.411 ===\n",
      "train loss:1.9967463786360486\n",
      "train loss:1.9500732612104732\n",
      "train loss:1.951750099256534\n",
      "=== epoch:157, train acc:0.5166666666666667, test acc:0.4119 ===\n",
      "train loss:1.9501854821170386\n",
      "train loss:1.9508032838568894\n",
      "train loss:1.9612127161841593\n",
      "=== epoch:158, train acc:0.51, test acc:0.4172 ===\n",
      "train loss:1.9690908041167214\n",
      "train loss:2.025071857791109\n",
      "train loss:1.9105176502282761\n",
      "=== epoch:159, train acc:0.5366666666666666, test acc:0.4267 ===\n",
      "train loss:1.9202528184042977\n",
      "train loss:1.970831851356387\n",
      "train loss:1.9174535823561334\n",
      "=== epoch:160, train acc:0.5266666666666666, test acc:0.4246 ===\n",
      "train loss:1.9159408590430909\n",
      "train loss:1.9285027119849534\n",
      "train loss:1.9108355358568665\n",
      "=== epoch:161, train acc:0.5166666666666667, test acc:0.42 ===\n",
      "train loss:2.019245238566937\n",
      "train loss:1.9553397096870202\n",
      "train loss:1.96611532106063\n",
      "=== epoch:162, train acc:0.5333333333333333, test acc:0.4254 ===\n",
      "train loss:1.9681076178082741\n",
      "train loss:2.0249974884604547\n",
      "train loss:1.9185340610386408\n",
      "=== epoch:163, train acc:0.54, test acc:0.4283 ===\n",
      "train loss:1.9654953244776023\n",
      "train loss:1.9312912438112861\n",
      "train loss:1.8929066507753152\n",
      "=== epoch:164, train acc:0.5433333333333333, test acc:0.4306 ===\n",
      "train loss:1.9391396546994255\n",
      "train loss:1.8726769490508992\n",
      "train loss:1.9425497266779725\n",
      "=== epoch:165, train acc:0.54, test acc:0.4327 ===\n",
      "train loss:1.8620897042237692\n",
      "train loss:1.9574244713147908\n",
      "train loss:1.94630559869814\n",
      "=== epoch:166, train acc:0.5433333333333333, test acc:0.4358 ===\n",
      "train loss:1.9545077240702287\n",
      "train loss:1.925561428329108\n",
      "train loss:1.8379078894709588\n",
      "=== epoch:167, train acc:0.5366666666666666, test acc:0.4347 ===\n",
      "train loss:1.9203384609913305\n",
      "train loss:1.9153566121984755\n",
      "train loss:1.928143570448239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:168, train acc:0.5366666666666666, test acc:0.4393 ===\n",
      "train loss:1.9446891732172487\n",
      "train loss:1.8724257259566581\n",
      "train loss:1.9155160483880647\n",
      "=== epoch:169, train acc:0.5466666666666666, test acc:0.4441 ===\n",
      "train loss:1.8794564596951924\n",
      "train loss:1.8995357839018707\n",
      "train loss:1.869584289793693\n",
      "=== epoch:170, train acc:0.55, test acc:0.4461 ===\n",
      "train loss:1.930392436714514\n",
      "train loss:1.851772551579772\n",
      "train loss:1.9448428202554526\n",
      "=== epoch:171, train acc:0.5466666666666666, test acc:0.4483 ===\n",
      "train loss:1.8768637973122742\n",
      "train loss:1.8456289398735344\n",
      "train loss:1.8756582730343796\n",
      "=== epoch:172, train acc:0.5533333333333333, test acc:0.4436 ===\n",
      "train loss:1.8712143385097395\n",
      "train loss:1.8624491736991287\n",
      "train loss:1.893029855167167\n",
      "=== epoch:173, train acc:0.5433333333333333, test acc:0.4384 ===\n",
      "train loss:1.8906794914965885\n",
      "train loss:1.8458572541665956\n",
      "train loss:1.805861797231954\n",
      "=== epoch:174, train acc:0.5433333333333333, test acc:0.4422 ===\n",
      "train loss:1.878039166378984\n",
      "train loss:1.8266570897189052\n",
      "train loss:1.8603489790749481\n",
      "=== epoch:175, train acc:0.5466666666666666, test acc:0.4425 ===\n",
      "train loss:1.86777822388344\n",
      "train loss:1.8532253321126646\n",
      "train loss:1.8381391217230723\n",
      "=== epoch:176, train acc:0.5533333333333333, test acc:0.4421 ===\n",
      "train loss:1.8114776190971682\n",
      "train loss:1.8322339375191954\n",
      "train loss:1.8361027815712205\n",
      "=== epoch:177, train acc:0.5566666666666666, test acc:0.4407 ===\n",
      "train loss:1.8381670385278062\n",
      "train loss:1.8846419652860384\n",
      "train loss:1.9146967501856724\n",
      "=== epoch:178, train acc:0.5566666666666666, test acc:0.4451 ===\n",
      "train loss:1.8263961063488825\n",
      "train loss:1.8314963526457406\n",
      "train loss:1.8873646743495762\n",
      "=== epoch:179, train acc:0.5566666666666666, test acc:0.4432 ===\n",
      "train loss:1.8045157379015635\n",
      "train loss:1.843357398927828\n",
      "train loss:1.7737372902061883\n",
      "=== epoch:180, train acc:0.5566666666666666, test acc:0.4433 ===\n",
      "train loss:1.8635423008834948\n",
      "train loss:1.8153921626723104\n",
      "train loss:1.8095617353347648\n",
      "=== epoch:181, train acc:0.56, test acc:0.4473 ===\n",
      "train loss:1.7822147914662942\n",
      "train loss:1.8087428565151586\n",
      "train loss:1.8214272896796802\n",
      "=== epoch:182, train acc:0.5533333333333333, test acc:0.438 ===\n",
      "train loss:1.8867967263425327\n",
      "train loss:1.8104387366764998\n",
      "train loss:1.866433336783561\n",
      "=== epoch:183, train acc:0.5633333333333334, test acc:0.4387 ===\n",
      "train loss:1.8210042163857951\n",
      "train loss:1.793090575456628\n",
      "train loss:1.7952962564409816\n",
      "=== epoch:184, train acc:0.5633333333333334, test acc:0.4424 ===\n",
      "train loss:1.6887832525906248\n",
      "train loss:1.8257850995678166\n",
      "train loss:1.75090196908773\n",
      "=== epoch:185, train acc:0.5666666666666667, test acc:0.4469 ===\n",
      "train loss:1.7771033958474525\n",
      "train loss:1.7777606847485017\n",
      "train loss:1.7823965080740678\n",
      "=== epoch:186, train acc:0.5666666666666667, test acc:0.4492 ===\n",
      "train loss:1.7825449178343937\n",
      "train loss:1.802793340085286\n",
      "train loss:1.7403674725851979\n",
      "=== epoch:187, train acc:0.57, test acc:0.447 ===\n",
      "train loss:1.8309897085006273\n",
      "train loss:1.8393511171269354\n",
      "train loss:1.7814110966873684\n",
      "=== epoch:188, train acc:0.56, test acc:0.4478 ===\n",
      "train loss:1.7860724972150883\n",
      "train loss:1.774408669733592\n",
      "train loss:1.8094966635494183\n",
      "=== epoch:189, train acc:0.5666666666666667, test acc:0.4487 ===\n",
      "train loss:1.7959620640698006\n",
      "train loss:1.7105055898341086\n",
      "train loss:1.7486431388944266\n",
      "=== epoch:190, train acc:0.57, test acc:0.4527 ===\n",
      "train loss:1.771874535512059\n",
      "train loss:1.818723898770882\n",
      "train loss:1.7589038043145542\n",
      "=== epoch:191, train acc:0.57, test acc:0.4556 ===\n",
      "train loss:1.7983849844807818\n",
      "train loss:1.6998690650654005\n",
      "train loss:1.788060735142292\n",
      "=== epoch:192, train acc:0.5733333333333334, test acc:0.4608 ===\n",
      "train loss:1.7381911376564048\n",
      "train loss:1.7397594702774988\n",
      "train loss:1.7085824067916258\n",
      "=== epoch:193, train acc:0.5766666666666667, test acc:0.459 ===\n",
      "train loss:1.7387757197889462\n",
      "train loss:1.6663645299055645\n",
      "train loss:1.7285400865310572\n",
      "=== epoch:194, train acc:0.5733333333333334, test acc:0.4599 ===\n",
      "train loss:1.6559196542406096\n",
      "train loss:1.7828516845520912\n",
      "train loss:1.7582913561970708\n",
      "=== epoch:195, train acc:0.5866666666666667, test acc:0.466 ===\n",
      "train loss:1.763559982180787\n",
      "train loss:1.6682944909699087\n",
      "train loss:1.676488268877998\n",
      "=== epoch:196, train acc:0.5866666666666667, test acc:0.4648 ===\n",
      "train loss:1.7382201886716373\n",
      "train loss:1.717778725806732\n",
      "train loss:1.682287136046344\n",
      "=== epoch:197, train acc:0.5866666666666667, test acc:0.4683 ===\n",
      "train loss:1.7360568412545905\n",
      "train loss:1.7115504949797116\n",
      "train loss:1.7073926773369974\n",
      "=== epoch:198, train acc:0.5866666666666667, test acc:0.4681 ===\n",
      "train loss:1.7019455537709929\n",
      "train loss:1.712800767085413\n",
      "train loss:1.7298089904857314\n",
      "=== epoch:199, train acc:0.5933333333333334, test acc:0.4815 ===\n",
      "train loss:1.6896782547849503\n",
      "train loss:1.7072650866057943\n",
      "train loss:1.6443976929035597\n",
      "=== epoch:200, train acc:0.6033333333333334, test acc:0.4887 ===\n",
      "train loss:1.6089100677470158\n",
      "train loss:1.6320048934137066\n",
      "train loss:1.6297267883416644\n",
      "=== epoch:201, train acc:0.5966666666666667, test acc:0.4864 ===\n",
      "train loss:1.63093241401417\n",
      "train loss:1.6283023009265876\n",
      "train loss:1.6375852113133984\n",
      "=== epoch:202, train acc:0.6, test acc:0.4911 ===\n",
      "train loss:1.6032370812589136\n",
      "train loss:1.6555396070712391\n",
      "train loss:1.6482432576285087\n",
      "=== epoch:203, train acc:0.6033333333333334, test acc:0.4899 ===\n",
      "train loss:1.6791643650258234\n",
      "train loss:1.639420348310208\n",
      "train loss:1.7756936978415323\n",
      "=== epoch:204, train acc:0.6, test acc:0.4875 ===\n",
      "train loss:1.6558840858040644\n",
      "train loss:1.7394632392899698\n",
      "train loss:1.6904755636815956\n",
      "=== epoch:205, train acc:0.6066666666666667, test acc:0.491 ===\n",
      "train loss:1.660549052155114\n",
      "train loss:1.5560194687925957\n",
      "train loss:1.6099264759337921\n",
      "=== epoch:206, train acc:0.61, test acc:0.4977 ===\n",
      "train loss:1.5394844588791319\n",
      "train loss:1.6289241370699967\n",
      "train loss:1.5365212953189453\n",
      "=== epoch:207, train acc:0.6066666666666667, test acc:0.496 ===\n",
      "train loss:1.6151794535962947\n",
      "train loss:1.5576774157127726\n",
      "train loss:1.620930899877814\n",
      "=== epoch:208, train acc:0.6033333333333334, test acc:0.4941 ===\n",
      "train loss:1.6298159844859208\n",
      "train loss:1.6142345514680252\n",
      "train loss:1.6035843895493038\n",
      "=== epoch:209, train acc:0.6066666666666667, test acc:0.4924 ===\n",
      "train loss:1.6554994730252417\n",
      "train loss:1.6735963358636263\n",
      "train loss:1.5792890111145987\n",
      "=== epoch:210, train acc:0.6, test acc:0.4963 ===\n",
      "train loss:1.596512130878373\n",
      "train loss:1.5712222672496514\n",
      "train loss:1.5733656844130979\n",
      "=== epoch:211, train acc:0.6, test acc:0.4923 ===\n",
      "train loss:1.5745882615458298\n",
      "train loss:1.551885180488181\n",
      "train loss:1.5768561485668247\n",
      "=== epoch:212, train acc:0.6066666666666667, test acc:0.5006 ===\n",
      "train loss:1.5476465947195979\n",
      "train loss:1.7252196038831606\n",
      "train loss:1.5348909918715103\n",
      "=== epoch:213, train acc:0.6166666666666667, test acc:0.5088 ===\n",
      "train loss:1.6185769786774142\n",
      "train loss:1.50967619735141\n",
      "train loss:1.5008195885321538\n",
      "=== epoch:214, train acc:0.6133333333333333, test acc:0.5 ===\n",
      "train loss:1.5900731976907472\n",
      "train loss:1.57982965432565\n",
      "train loss:1.554435984793024\n",
      "=== epoch:215, train acc:0.6166666666666667, test acc:0.5045 ===\n",
      "train loss:1.5726142315054232\n",
      "train loss:1.4961628552338526\n",
      "train loss:1.6474732419131695\n",
      "=== epoch:216, train acc:0.62, test acc:0.5059 ===\n",
      "train loss:1.4919782243744486\n",
      "train loss:1.5105620224926026\n",
      "train loss:1.4574064210122555\n",
      "=== epoch:217, train acc:0.62, test acc:0.5019 ===\n",
      "train loss:1.5302831366659175\n",
      "train loss:1.4872037329691805\n",
      "train loss:1.4978320388399708\n",
      "=== epoch:218, train acc:0.6233333333333333, test acc:0.5036 ===\n",
      "train loss:1.6796447347395584\n",
      "train loss:1.5494512036190407\n",
      "train loss:1.5007338175225997\n",
      "=== epoch:219, train acc:0.6366666666666667, test acc:0.5136 ===\n",
      "train loss:1.4715816500119587\n",
      "train loss:1.4262089578581507\n",
      "train loss:1.470449238491645\n",
      "=== epoch:220, train acc:0.64, test acc:0.5173 ===\n",
      "train loss:1.5586089504713638\n",
      "train loss:1.5151155437007773\n",
      "train loss:1.515284800067368\n",
      "=== epoch:221, train acc:0.6366666666666667, test acc:0.5165 ===\n",
      "train loss:1.4646419336083907\n",
      "train loss:1.3875139286214095\n",
      "train loss:1.376975648507677\n",
      "=== epoch:222, train acc:0.6333333333333333, test acc:0.5085 ===\n",
      "train loss:1.5194262425823863\n",
      "train loss:1.563286346975259\n",
      "train loss:1.5110147870797073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:223, train acc:0.64, test acc:0.5148 ===\n",
      "train loss:1.3652911247574948\n",
      "train loss:1.4896793655630691\n",
      "train loss:1.4685876069616486\n",
      "=== epoch:224, train acc:0.6433333333333333, test acc:0.5121 ===\n",
      "train loss:1.4856538159309272\n",
      "train loss:1.3860763778755003\n",
      "train loss:1.4032020039482236\n",
      "=== epoch:225, train acc:0.6433333333333333, test acc:0.5119 ===\n",
      "train loss:1.5443519584587444\n",
      "train loss:1.3841065473812124\n",
      "train loss:1.4670450350118955\n",
      "=== epoch:226, train acc:0.6433333333333333, test acc:0.5206 ===\n",
      "train loss:1.46306907965561\n",
      "train loss:1.4109345752180813\n",
      "train loss:1.3689111390364963\n",
      "=== epoch:227, train acc:0.6466666666666666, test acc:0.5223 ===\n",
      "train loss:1.506018640756899\n",
      "train loss:1.3221409525953858\n",
      "train loss:1.5855991952387785\n",
      "=== epoch:228, train acc:0.65, test acc:0.5273 ===\n",
      "train loss:1.4149115715492968\n",
      "train loss:1.4847109711675222\n",
      "train loss:1.3463542408279765\n",
      "=== epoch:229, train acc:0.64, test acc:0.5251 ===\n",
      "train loss:1.4054554026847057\n",
      "train loss:1.43429431716941\n",
      "train loss:1.4196335001873346\n",
      "=== epoch:230, train acc:0.6433333333333333, test acc:0.5253 ===\n",
      "train loss:1.498868453515261\n",
      "train loss:1.3444421272354756\n",
      "train loss:1.3639455483915415\n",
      "=== epoch:231, train acc:0.6366666666666667, test acc:0.5243 ===\n",
      "train loss:1.4220371712649038\n",
      "train loss:1.425577473842796\n",
      "train loss:1.359427853689121\n",
      "=== epoch:232, train acc:0.6466666666666666, test acc:0.5276 ===\n",
      "train loss:1.4318642438253317\n",
      "train loss:1.3150939683580114\n",
      "train loss:1.470673698722365\n",
      "=== epoch:233, train acc:0.6433333333333333, test acc:0.5297 ===\n",
      "train loss:1.2757899344135608\n",
      "train loss:1.3249434016468424\n",
      "train loss:1.248264522680759\n",
      "=== epoch:234, train acc:0.64, test acc:0.5293 ===\n",
      "train loss:1.344420651438961\n",
      "train loss:1.4186995132359248\n",
      "train loss:1.454247872837256\n",
      "=== epoch:235, train acc:0.64, test acc:0.5308 ===\n",
      "train loss:1.3669945917320256\n",
      "train loss:1.3992744909645523\n",
      "train loss:1.3673172825788869\n",
      "=== epoch:236, train acc:0.66, test acc:0.5367 ===\n",
      "train loss:1.2735999782556484\n",
      "train loss:1.4997141818762336\n",
      "train loss:1.2693756744218858\n",
      "=== epoch:237, train acc:0.6466666666666666, test acc:0.5334 ===\n",
      "train loss:1.3867926834987585\n",
      "train loss:1.3350919527277085\n",
      "train loss:1.3341916373528644\n",
      "=== epoch:238, train acc:0.6533333333333333, test acc:0.5311 ===\n",
      "train loss:1.3750427864199886\n",
      "train loss:1.2964382765760234\n",
      "train loss:1.2613474827685305\n",
      "=== epoch:239, train acc:0.6533333333333333, test acc:0.5306 ===\n",
      "train loss:1.270244940812905\n",
      "train loss:1.3279012382103348\n",
      "train loss:1.2739720762609472\n",
      "=== epoch:240, train acc:0.6633333333333333, test acc:0.537 ===\n",
      "train loss:1.5072979419719135\n",
      "train loss:1.3248573511549504\n",
      "train loss:1.2820256064383526\n",
      "=== epoch:241, train acc:0.67, test acc:0.5436 ===\n",
      "train loss:1.273952778333003\n",
      "train loss:1.2688868598339302\n",
      "train loss:1.2522053941681193\n",
      "=== epoch:242, train acc:0.68, test acc:0.5485 ===\n",
      "train loss:1.3891649249330285\n",
      "train loss:1.234816015957199\n",
      "train loss:1.4309820862591274\n",
      "=== epoch:243, train acc:0.69, test acc:0.5584 ===\n",
      "train loss:1.3042795286784719\n",
      "train loss:1.2476579580735685\n",
      "train loss:1.218674609247954\n",
      "=== epoch:244, train acc:0.7, test acc:0.5588 ===\n",
      "train loss:1.3129943042764052\n",
      "train loss:1.2291985716184317\n",
      "train loss:1.2885963367855167\n",
      "=== epoch:245, train acc:0.6966666666666667, test acc:0.5582 ===\n",
      "train loss:1.3714164463245617\n",
      "train loss:1.229303327377116\n",
      "train loss:1.2691536440989966\n",
      "=== epoch:246, train acc:0.7066666666666667, test acc:0.5617 ===\n",
      "train loss:1.2386528443366678\n",
      "train loss:1.20465183073087\n",
      "train loss:1.1633988422198425\n",
      "=== epoch:247, train acc:0.6966666666666667, test acc:0.559 ===\n",
      "train loss:1.244976436381661\n",
      "train loss:1.173546882902168\n",
      "train loss:1.3841708906683194\n",
      "=== epoch:248, train acc:0.7, test acc:0.5607 ===\n",
      "train loss:1.2832984820578566\n",
      "train loss:1.2339727138044456\n",
      "train loss:1.1153775531480472\n",
      "=== epoch:249, train acc:0.6933333333333334, test acc:0.5619 ===\n",
      "train loss:1.1724501904678986\n",
      "train loss:1.086852393979202\n",
      "train loss:1.1854037565988353\n",
      "=== epoch:250, train acc:0.6866666666666666, test acc:0.5496 ===\n",
      "train loss:1.2548411945677571\n",
      "train loss:1.2583150020797456\n",
      "train loss:1.1957610100185925\n",
      "=== epoch:251, train acc:0.6833333333333333, test acc:0.5491 ===\n",
      "train loss:1.2366452616037145\n",
      "train loss:1.2836939914711436\n",
      "train loss:1.1414606918038082\n",
      "=== epoch:252, train acc:0.6866666666666666, test acc:0.5522 ===\n",
      "train loss:1.186106013553081\n",
      "train loss:1.2091464675206398\n",
      "train loss:1.0751922501161761\n",
      "=== epoch:253, train acc:0.6833333333333333, test acc:0.5489 ===\n",
      "train loss:1.121590439252558\n",
      "train loss:1.3413811307610386\n",
      "train loss:1.2518887342646456\n",
      "=== epoch:254, train acc:0.6833333333333333, test acc:0.5478 ===\n",
      "train loss:1.2500774123847491\n",
      "train loss:1.2159533723298799\n",
      "train loss:1.3076692658420035\n",
      "=== epoch:255, train acc:0.6833333333333333, test acc:0.5519 ===\n",
      "train loss:1.1451084632155106\n",
      "train loss:1.1625861180016641\n",
      "train loss:1.131508664001643\n",
      "=== epoch:256, train acc:0.7, test acc:0.56 ===\n",
      "train loss:1.2505404598862069\n",
      "train loss:1.1350670578229463\n",
      "train loss:1.3668875726967749\n",
      "=== epoch:257, train acc:0.7066666666666667, test acc:0.5638 ===\n",
      "train loss:1.3237919371202609\n",
      "train loss:1.1170266362278003\n",
      "train loss:1.194943700736517\n",
      "=== epoch:258, train acc:0.71, test acc:0.5678 ===\n",
      "train loss:1.0801219490655232\n",
      "train loss:1.2030307488945997\n",
      "train loss:1.1654221539594658\n",
      "=== epoch:259, train acc:0.7233333333333334, test acc:0.5653 ===\n",
      "train loss:1.1376230231614433\n",
      "train loss:1.1338288583488372\n",
      "train loss:1.1311019912635456\n",
      "=== epoch:260, train acc:0.7133333333333334, test acc:0.5608 ===\n",
      "train loss:1.0887974870113135\n",
      "train loss:1.199871877898994\n",
      "train loss:1.1311368490759\n",
      "=== epoch:261, train acc:0.7033333333333334, test acc:0.5568 ===\n",
      "train loss:1.128479184744206\n",
      "train loss:1.1684962653504916\n",
      "train loss:1.1098190598911513\n",
      "=== epoch:262, train acc:0.69, test acc:0.5575 ===\n",
      "train loss:1.2262443846342708\n",
      "train loss:1.040407784116379\n",
      "train loss:1.1189781938874785\n",
      "=== epoch:263, train acc:0.6966666666666667, test acc:0.5543 ===\n",
      "train loss:1.1062102302988932\n",
      "train loss:1.0506530983261817\n",
      "train loss:1.2983664376202106\n",
      "=== epoch:264, train acc:0.6933333333333334, test acc:0.5574 ===\n",
      "train loss:1.2477644640368108\n",
      "train loss:1.0298651154564207\n",
      "train loss:1.084231002701352\n",
      "=== epoch:265, train acc:0.6866666666666666, test acc:0.5514 ===\n",
      "train loss:1.2549326017181663\n",
      "train loss:1.1046048564848658\n",
      "train loss:1.1664246682797377\n",
      "=== epoch:266, train acc:0.6866666666666666, test acc:0.5571 ===\n",
      "train loss:1.1594716227457047\n",
      "train loss:1.1014327842302545\n",
      "train loss:1.0148883478768362\n",
      "=== epoch:267, train acc:0.6933333333333334, test acc:0.5596 ===\n",
      "train loss:1.0583948467064894\n",
      "train loss:0.9363951972513328\n",
      "train loss:1.212987966900454\n",
      "=== epoch:268, train acc:0.7066666666666667, test acc:0.5663 ===\n",
      "train loss:1.07692822359225\n",
      "train loss:1.229030774812804\n",
      "train loss:1.197854434754457\n",
      "=== epoch:269, train acc:0.71, test acc:0.5671 ===\n",
      "train loss:1.1103425654386232\n",
      "train loss:1.0121643387552333\n",
      "train loss:1.148385690520932\n",
      "=== epoch:270, train acc:0.7166666666666667, test acc:0.57 ===\n",
      "train loss:1.1927198500663145\n",
      "train loss:1.0734753182971615\n",
      "train loss:1.180105837975044\n",
      "=== epoch:271, train acc:0.72, test acc:0.5747 ===\n",
      "train loss:1.1538786591644672\n",
      "train loss:1.1317132096153066\n",
      "train loss:1.0658171812025348\n",
      "=== epoch:272, train acc:0.7166666666666667, test acc:0.5777 ===\n",
      "train loss:1.0388304578059637\n",
      "train loss:0.9687347892515179\n",
      "train loss:1.0038018372634827\n",
      "=== epoch:273, train acc:0.72, test acc:0.5827 ===\n",
      "train loss:1.0520362426882979\n",
      "train loss:1.1920491917006057\n",
      "train loss:0.9440524612941893\n",
      "=== epoch:274, train acc:0.72, test acc:0.5782 ===\n",
      "train loss:1.00452142100357\n",
      "train loss:0.993321135111355\n",
      "train loss:1.0142568303884503\n",
      "=== epoch:275, train acc:0.7133333333333334, test acc:0.5763 ===\n",
      "train loss:1.122792483368438\n",
      "train loss:1.1297323615019264\n",
      "train loss:0.9903417837837614\n",
      "=== epoch:276, train acc:0.7233333333333334, test acc:0.5823 ===\n",
      "train loss:1.0745340289963383\n",
      "train loss:1.0789932084428113\n",
      "train loss:1.0624857188273777\n",
      "=== epoch:277, train acc:0.73, test acc:0.5815 ===\n",
      "train loss:1.0563338865321699\n",
      "train loss:1.1123885176402781\n",
      "train loss:1.0359025051162838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:278, train acc:0.7266666666666667, test acc:0.5818 ===\n",
      "train loss:1.0147008351473883\n",
      "train loss:1.0131457966463606\n",
      "train loss:0.973227803443693\n",
      "=== epoch:279, train acc:0.7333333333333333, test acc:0.5818 ===\n",
      "train loss:1.0585018752133413\n",
      "train loss:0.9982502049202411\n",
      "train loss:1.0616496788490704\n",
      "=== epoch:280, train acc:0.7066666666666667, test acc:0.5776 ===\n",
      "train loss:0.9003228241925926\n",
      "train loss:1.1859673069306553\n",
      "train loss:1.1040169301806075\n",
      "=== epoch:281, train acc:0.7266666666666667, test acc:0.5819 ===\n",
      "train loss:1.1136300688227063\n",
      "train loss:0.9693807882060874\n",
      "train loss:0.8808120963750854\n",
      "=== epoch:282, train acc:0.7066666666666667, test acc:0.5714 ===\n",
      "train loss:1.0824166641353457\n",
      "train loss:1.0317085908643957\n",
      "train loss:0.9397518010742535\n",
      "=== epoch:283, train acc:0.7033333333333334, test acc:0.5709 ===\n",
      "train loss:1.1002160394522549\n",
      "train loss:0.9639745758971634\n",
      "train loss:1.0489179917627718\n",
      "=== epoch:284, train acc:0.7166666666666667, test acc:0.5769 ===\n",
      "train loss:0.9502774881241441\n",
      "train loss:0.979775268656512\n",
      "train loss:1.0110770035052266\n",
      "=== epoch:285, train acc:0.7166666666666667, test acc:0.5742 ===\n",
      "train loss:0.9699833554479603\n",
      "train loss:0.9522059049146168\n",
      "train loss:1.0399569920040719\n",
      "=== epoch:286, train acc:0.7, test acc:0.5735 ===\n",
      "train loss:0.9944657885415122\n",
      "train loss:0.9441411398383147\n",
      "train loss:1.087879342714015\n",
      "=== epoch:287, train acc:0.7066666666666667, test acc:0.575 ===\n",
      "train loss:1.0025061928761703\n",
      "train loss:0.9543954960803783\n",
      "train loss:0.9683917514327383\n",
      "=== epoch:288, train acc:0.7, test acc:0.5772 ===\n",
      "train loss:1.0261828946502758\n",
      "train loss:1.0939266932388703\n",
      "train loss:0.9540171963124799\n",
      "=== epoch:289, train acc:0.7033333333333334, test acc:0.5818 ===\n",
      "train loss:0.9451693599336695\n",
      "train loss:0.898219589496668\n",
      "train loss:1.000281324868146\n",
      "=== epoch:290, train acc:0.7166666666666667, test acc:0.5836 ===\n",
      "train loss:0.8651586745220938\n",
      "train loss:0.915966581051441\n",
      "train loss:0.9617780467480506\n",
      "=== epoch:291, train acc:0.7033333333333334, test acc:0.5827 ===\n",
      "train loss:0.9634971434915899\n",
      "train loss:0.8493922765237382\n",
      "train loss:1.0628777791104362\n",
      "=== epoch:292, train acc:0.73, test acc:0.5888 ===\n",
      "train loss:0.9854672358057179\n",
      "train loss:0.9204541635311579\n",
      "train loss:0.8824113875192878\n",
      "=== epoch:293, train acc:0.7266666666666667, test acc:0.5885 ===\n",
      "train loss:1.0054014551487145\n",
      "train loss:0.8584056157838249\n",
      "train loss:0.8749677544507635\n",
      "=== epoch:294, train acc:0.72, test acc:0.5868 ===\n",
      "train loss:0.8816176842816092\n",
      "train loss:1.062973099626843\n",
      "train loss:1.0766538380088804\n",
      "=== epoch:295, train acc:0.7133333333333334, test acc:0.5854 ===\n",
      "train loss:0.9215555275822415\n",
      "train loss:1.0229163697671328\n",
      "train loss:1.0229599184092473\n",
      "=== epoch:296, train acc:0.7166666666666667, test acc:0.5916 ===\n",
      "train loss:0.9397437501349793\n",
      "train loss:1.0631023369644323\n",
      "train loss:0.9037496548768468\n",
      "=== epoch:297, train acc:0.7266666666666667, test acc:0.5944 ===\n",
      "train loss:0.9386447291243164\n",
      "train loss:0.9207186054051115\n",
      "train loss:0.8234138015640642\n",
      "=== epoch:298, train acc:0.72, test acc:0.5828 ===\n",
      "train loss:0.8970529037755708\n",
      "train loss:0.9231570237696629\n",
      "train loss:0.7908779920711021\n",
      "=== epoch:299, train acc:0.7266666666666667, test acc:0.583 ===\n",
      "train loss:1.003824045276945\n",
      "train loss:0.9651491364662428\n",
      "train loss:0.9740723467117227\n",
      "=== epoch:300, train acc:0.7166666666666667, test acc:0.5814 ===\n",
      "train loss:1.1016232907510848\n",
      "train loss:0.9231684102190129\n",
      "train loss:0.8412993423703073\n",
      "=== epoch:301, train acc:0.74, test acc:0.5882 ===\n",
      "train loss:0.9428993905235825\n",
      "train loss:0.9891278637183483\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.5878\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.multi_layer_net_extend import MultiLayerNetExtend\n",
    "from common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 오버피팅을 재현하기 위해 학습 데이터 수를 줄임\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]\n",
    "\n",
    "# 드롭아웃 사용 유무와 비울 설정 ========================\n",
    "use_dropout = True  # 드롭아웃을 쓰지 않을 때는 False\n",
    "dropout_ratio = 0.2\n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
    "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=301, mini_batch_size=100,\n",
    "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
    "trainer.train()\n",
    "\n",
    "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list\n",
    "\n",
    "# 그래프 그리기==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-reputation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
